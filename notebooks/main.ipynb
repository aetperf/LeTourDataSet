{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "a6aa1c8e-04bd-4f2b-abc0-82632ffd2439"
   },
   "source": [
    "# LeTour data set \n",
    "This file downloads raw data about every rider of every Tour de France (from 1903 up to 2020). This data will then be postprocessed and stored in CSV format.\n",
    "Executing this notebook might take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "effcdea0-693c-4387-81e6-41ea9fa951e4"
   },
   "source": [
    "## 1) Retrieve urls for data extract\n",
    "First we generate the urls that we need to download the raw HTML pages from the `letour.fr` website to work offline from here on. The dataframe dflink will stores the respective url for each year.\n",
    "Take a look at `view-source:https://www.letour.fr/en/history` (at around line 1143-1890).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "1859351a-eca4-49e8-8840-f54e504b4b38",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "d1b12802-1d6d-422b-828b-79b24bc91744",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PREFIX = \"http://www.letour.fr\"\n",
    "HISTORYPAGE = \"https://www.letour.fr/en/history\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "00b91543-17b5-423a-a4e0-a6b4dbd67735",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Accept\": \"text/html\",\n",
    "    \"User-Agent\": \"python-requests/1.2.0\",\n",
    "    \"Accept-Charset\": \"utf-8\",\n",
    "    \"accept-encoding\": \"deflate, br\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "8561b6ea-dfef-46f7-8c6f-0c0f86bfa002",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "resulthistpage = requests.get(HISTORYPAGE, allow_redirects=True, headers=headers)\n",
    "souphistory = BeautifulSoup(resulthistpage.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "459b1f6d-a548-4bc1-bc8e-63674337c425",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find select tag for histo links\n",
    "select_tag_histo = souphistory.find_all(\"button\", {\"class\": \"dateTabs__link\"})\n",
    "\n",
    "LH = [x[\"data-tabs-ajax\"] for x in select_tag_histo]\n",
    "\n",
    "dflink = pd.DataFrame({\"TDFHistorylink\": LH})\n",
    "dflink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "ed3c9e7d-43c9-4fd9-8f79-771fe9fddc44"
   },
   "source": [
    "## 2) Get data from HTML pages and convert results to dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "66c30e6c-0a98-492e-ba77-e5602479f608"
   },
   "source": [
    "### 2.1) Create function that convert HHh mm' ss'' to seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "c30574e5-d69c-4eff-ac54-2577577fd470",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcTotalSeconds(row, mode):\n",
    "    val = sum(\n",
    "        x * int(t)\n",
    "        for x, t in zip(\n",
    "            [3600, 60, 1],\n",
    "            row.replace(\"h\", \":\")\n",
    "            .replace(\"'\", \":\")\n",
    "            .replace('\"', \":\")\n",
    "            .replace(\" \", \"\")\n",
    "            .replace(\"+\", \"\")\n",
    "            .replace(\"-\", \"0\")\n",
    "            .split(\":\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if (mode == \"Gap\") and val > 180000:\n",
    "        val = 0\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "28ecdf5d-db79-4994-825f-9b228a278070"
   },
   "source": [
    "### 2.2) Create a function that will retrieve elements from a source HTML page located on an input url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "70622fa0-f5af-4bda-b433-e2065b2db03e",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getstagesNrank(i_url):\n",
    "    resultfull = requests.get(i_url, allow_redirects=True)\n",
    "    result = resultfull.text\n",
    "    resultstatus = resultfull.status_code\n",
    "\n",
    "    print(i_url + \" ==> HTTP STATUS = \" + str(resultstatus))\n",
    "\n",
    "    soup = BeautifulSoup(result, \"html.parser\")\n",
    "    h = soup.find(\"h3\")\n",
    "    year = int(h.text[-4:])\n",
    "\n",
    "    # Find select tag\n",
    "    select_tag = soup.find(\"select\")\n",
    "\n",
    "    # find all option tag inside select tag\n",
    "    options = select_tag.find_all(\"option\")\n",
    "\n",
    "    cols = [\"Year\", \"TotalTDFDistance\", \"Stage\"]\n",
    "    lst = []\n",
    "\n",
    "    # search for stages\n",
    "    distance = soup.select(\"[class~=statsInfos__number]\")[1].contents\n",
    "\n",
    "    # search for distance of the TDF edition\n",
    "    for option in options:\n",
    "        lst.append([year, int(distance[0].replace(\" \", \"\")), option.text])\n",
    "\n",
    "    dfstages = pd.DataFrame(lst, columns=cols)\n",
    "\n",
    "    # Find select tag for ranking racers\n",
    "    rankingTable = soup.find(\"table\")\n",
    "\n",
    "    dfrank = pd.read_html(str(rankingTable))[0]\n",
    "\n",
    "    dfrank[\"Year\"] = year\n",
    "    dfrank[\"Distance (km)\"] = int(distance[0].replace(\" \", \"\"))\n",
    "    dfrank[\"Number of stages\"] = len(dfstages)\n",
    "    dfrank[\"TotalSeconds\"] = dfrank[\"Times\"].apply(\n",
    "        lambda x: calcTotalSeconds(x, \"Total\")\n",
    "    )\n",
    "    dfrank[\"GapSeconds\"] = dfrank[\"Gap\"].apply(lambda x: calcTotalSeconds(x, \"Gap\"))\n",
    "\n",
    "    return dfstages, dfrank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "cb608a73-e919-46fd-843f-ab76d1ccbcd9"
   },
   "source": [
    "### 2.3) Loop on the dflink dataframe to get data from each url source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "d7e093e9-68a8-479e-a029-ceb5c068669d",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfstagesrestmp = pd.DataFrame()\n",
    "dfrankrestmp = pd.DataFrame()\n",
    "\n",
    "for index, row in dflink.iterrows():\n",
    "    url = PREFIX + row[\"TDFHistorylink\"]\n",
    "    try:\n",
    "        if (\n",
    "            index >= 12\n",
    "        ):  # limit from 1919 (data need to be cleaned a little bit more before that)\n",
    "            dfstagesres, dfrankres = getstagesNrank(url)\n",
    "            dfstagesrestmp = pd.concat((dfstagesres, dfstagesrestmp), axis=0)\n",
    "            dfrankrestmp = pd.concat((dfrankres, dfrankrestmp), axis=0)\n",
    "\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "d7e093e9-68a8-479e-a029-ceb5c068669d",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfstageoutput = dfstagesrestmp.reset_index(drop=True)\n",
    "dfrankoutput = dfrankrestmp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "a6f4f902-d981-4789-8dca-9dfd69bf7d8e",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfrankoutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "f507d80d-eac4-4707-ae66-c27ad6110b0e"
   },
   "source": [
    "## 3) Clean up the data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "8d7f99b4-0d13-49e5-9019-5750c46eb948",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix result types\n",
    "dfrankoutput[\"ResultType\"] = \"time\"\n",
    "dfrankoutput.loc[dfrankoutput[\"Year\"].isin([1905, 1906, 1908]), \"ResultType\"] = \"null\"\n",
    "dfrankoutput.loc[\n",
    "    dfrankoutput[\"Year\"].isin([1907, 1909, 1910, 1911, 1912]), \"ResultType\"\n",
    "] = \"points\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "5d9f570c-5a9b-4dcf-97e8-9e9ce015d260",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix this weird bug for e.g. year 2006 and 1997\n",
    "for year in np.unique(dfrankoutput[\"Year\"]):\n",
    "    tmp = dfrankoutput[dfrankoutput[\"Year\"] == year].reset_index()\n",
    "    if tmp.loc[0][\"TotalSeconds\"] > tmp.loc[2][\"TotalSeconds\"]:\n",
    "        print(year)\n",
    "# Okay seems to be only for 2006 and 1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "c8f17e97-08fe-4ae5-880f-dc5f94968606",
    "language": "python",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = dfrankoutput[dfrankoutput[\"Year\"] == 2006].reset_index()\n",
    "ts = np.array(tmp[\"TotalSeconds\"])\n",
    "gs = np.array(tmp[\"GapSeconds\"])\n",
    "ts[1:] = ts[0] + gs[1:]\n",
    "\n",
    "dfrankoutput.loc[dfrankoutput[\"Year\"] == 2006, \"TotalSeconds\"] = ts\n",
    "\n",
    "tmp = dfrankoutput[dfrankoutput[\"Year\"] == 1997].reset_index()\n",
    "ts = np.array(tmp[\"TotalSeconds\"])\n",
    "gs = np.array(tmp[\"GapSeconds\"])\n",
    "ts[1:] = ts[0] + gs[1:]\n",
    "\n",
    "dfrankoutput.loc[dfrankoutput[\"Year\"] == 1997, \"TotalSeconds\"] = ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "azdata_cell_guid": "edd8e8aa-49d7-4175-90d0-62c52258cf5b"
   },
   "source": [
    "## 4) Write Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "dd5074fe-7f35-47a6-b1d8-e4456b0f05cb",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dfrankoutput.to_csv(\"../data/TDF_Riders_History.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "azdata_cell_guid": "3c7a71a5-941f-4d15-b3a2-0b36b6557617",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dfstageoutput.to_csv(\"../data/TDF_Stages_History.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
